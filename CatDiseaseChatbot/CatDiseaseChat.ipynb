{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "고양이 질병관련 챗봇\n",
    "(챗봇,워드클라우드//이후에 다른걸 추가해보기 일단 두개부터)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "챗봇"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "워드클라우드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\HJY310\\.venv\\lib\\site-packages\\gradio\\components\\chatbot.py:279: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from fuzzywuzzy import process\n",
    "import re\n",
    "\n",
    "# CSV 파일 로드 (경로를 실제 파일 경로로 변경해주세요)\n",
    "df = pd.read_csv(\"./data/cat_diseases.csv\", encoding='CP949')\n",
    "\n",
    "# Symptoms와 Description을 합쳐서 inputs 컬럼 생성\n",
    "#df['inputs'] = df['Symptoms'] + \" \" + df['Description']\n",
    "df['inputs'] = df['Symptoms'].fillna('') + \" \" + df['Description'].fillna('')\n",
    "\n",
    "\n",
    "# 텍스트 분할\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "texts = text_splitter.split_text(\"\\n\".join(df['inputs']))\n",
    "\n",
    "# 임베딩 모델 초기화\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# 벡터 데이터베이스 생성\n",
    "vectorstore = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "# ChatOllama 모델 초기화 (temperature 값 조정)\n",
    "#llm = ChatOllama(model=\"gemma2\", temperature=0.0)\n",
    "try:\n",
    "    llm = ChatOllama(model=\"gemma2\", temperature=0.0)\n",
    "except Exception as e:\n",
    "    print(f\"LLM 초기화 오류: {e}\")\n",
    "    llm = None\n",
    "\n",
    "\n",
    "# Question Generation Prompt\n",
    "question_generator_template = \"\"\"\n",
    "이전 대화 내역과 새로운 사용자 질문이 주어졌을 때, 검색을 위한 독립적인 질문으로 바꿔서 생성해주세요.\n",
    "\n",
    "이전 대화 내역:\n",
    "{chat_history}\n",
    "\n",
    "새로운 사용자 질문:\n",
    "{question}\n",
    "\n",
    "독립적인 질문:\n",
    "\"\"\"\n",
    "QUESTION_GENERATOR_PROMPT = PromptTemplate(input_variables=[\"chat_history\", \"question\"], template=question_generator_template)\n",
    "\n",
    "# Combine Documents Prompt (한국어 지시 강화 및 형식 명확화)\n",
    "combine_documents_template = \"\"\"\n",
    "당신은 경험 많은 고양이 수의사입니다. **모든 답변은 한국어만 사용하여, 어색함이 없도록 매우 자연스럽게 작성해야 합니다. 존댓말을 사용하여 정중하게 답변해야 합니다.** 외국어나 어색한 한국어 표현을 절대 사용하지 않도록 주의하십시오.\n",
    "\n",
    "사용자의 질문에 대해 다음과 같은 방식으로 답변해야 합니다.\n",
    "\n",
    "1.  질문에 대한 직접적인 답변을 **한국어로** 제공합니다.\n",
    "2.  필요한 경우, 추가적인 질문을 통해 상황을 명확히 파악하려고 노력해야 합니다. 예를 들어, 증상의 기간, 심각성, 다른 동반 증상 등을 **한국어로, 부드럽게** 물어볼 수 있습니다. (예: \"혹시 언제부터 그러셨나요?\", \"다른 불편한 점은 없으신가요?\")\n",
    "3.  가능한 원인 질병을 언급하고, 각 질병에 대한 간략한 설명을 **한국어로, 이해하기 쉽게** 제공합니다.\n",
    "4.  집에서 할 수 있는 조치와 동물병원 방문이 필요한 경우를 명확하게 구분하여 **한국어로, 친절하게** 안내합니다.\n",
    "5.  절대 진단이나 처방을 내리지 않고, 반드시 동물병원에 방문하여 정확한 진료를 받을 것을 **한국어로, 정중하게** 권장해야 합니다.\n",
    "\n",
    "검색된 문서:\n",
    "{context}\n",
    "\n",
    "사용자 질문:\n",
    "{question}\n",
    "\n",
    "답변:\n",
    "\"\"\"\n",
    "COMBINE_DOCUMENTS_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"], template=combine_documents_template)\n",
    "\n",
    "# Chain 생성\n",
    "question_generator = LLMChain(llm=llm, prompt=QUESTION_GENERATOR_PROMPT)\n",
    "doc_chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=COMBINE_DOCUMENTS_PROMPT)\n",
    "\n",
    "qa = ConversationalRetrievalChain(\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 1}),\n",
    "    combine_docs_chain=doc_chain,\n",
    "    question_generator=question_generator,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "# 입력한 채팅 공백이나 특수문자 예외처리\n",
    "def clean_text(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.replace(\" \", \"\")\n",
    "    return text.lower()\n",
    "\n",
    "# 질병 정보 검색 함수\n",
    "def search_disease_info(message):\n",
    "    best_match = process.extractOne(message, df['inputs'])\n",
    "    if best_match and best_match[1] > 80:\n",
    "        disease_info = df.loc[df['inputs'] == best_match[0]]\n",
    "        disease_name = disease_info['Disease'].values[0]\n",
    "        symptoms = disease_info['Symptoms'].values[0]\n",
    "        description = disease_info['Description'].values[0]\n",
    "        emergency = disease_info['Emergency'].values[0]\n",
    "        return f\"질병: {disease_name}\\n증상: {symptoms}\\n설명: {description}\\n응급상황 여부: {emergency}\"\n",
    "    return \"해당 질문에 대한 답변을 찾을 수 없습니다.\"\n",
    "\n",
    "# 고양이 질병에 대한 정보 제공하는 채팅 함수\n",
    "def chat(message, history):\n",
    "    cleaned_message = clean_text(message)\n",
    "    disease_info = search_disease_info(message)\n",
    "    return disease_info\n",
    "\n",
    "# Conversational Chat 함수 구현 (chat_history 관리)\n",
    "#def conversational_chat(message, history):\n",
    "#    global chat_history\n",
    "#    result = qa({\"question\": message, \"chat_history\": chat_history})\n",
    "#    chat_history = [(message, result[\"answer\"])]\n",
    "#    return result[\"answer\"]\n",
    "\n",
    "def conversational_chat(message, history=[]):\n",
    "    result = qa({\"question\": message, \"chat_history\": history})\n",
    "    history.append((message, result[\"answer\"]))\n",
    "    return result[\"answer\"]\n",
    "\n",
    "\n",
    "# Gradio 인터페이스 설정 (CSS 및 components 활용)\n",
    "with gr.Blocks(css=\"\"\"\n",
    ".chat-interface-container {\n",
    "    height: 650px;\n",
    "    max-height: 800px;\n",
    "    overflow-y: auto;\n",
    "    border: 3px solid #7193BD;\n",
    "    padding: 15px;\n",
    "    border-radius: 15px;\n",
    "}\n",
    ".message {\n",
    "    background-color: #F1E6BF !important;\n",
    "    white-space: pre-wrap !important; /* 긴 텍스트 줄바꿈 처리 */\n",
    "}\n",
    ".message.user {\n",
    "    background-color: #F1E6BF !important;\n",
    "    padding: 10px;\n",
    "    border-radius: 15px;\n",
    "}\n",
    ".message.ai {\n",
    "    background-color: #BED8EB !important;\n",
    "    padding: 10px;\n",
    "    border-radius: 15px;\n",
    "}\n",
    ".chat-title {\n",
    "    font-size: 35px !important; /* 글씨 크기 조정 */\n",
    "    color: #93B9D6 !important; /* 글씨 색상 조정 - 여기서 세미콜론 앞 공백 제거 */\n",
    "    text-align: center;\n",
    "    margin-bottom: 20px;\n",
    "    font-weight: bold !important; /* 글자 두께 조정 */\n",
    "}\n",
    ".description { \n",
    "    text-align: right !important; /* 텍스트 오른쪽 정렬 */ \n",
    "    color: #6D6875 !important;\n",
    "    font-weight: bold !important;\n",
    "    margin-bottom: 20px; /* 추가로 간격 조정 */\n",
    "}\n",
    "\"\"\") as demo:\n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\" 고양이 질병 AI 챗봇 \"):\n",
    "            chat_demo = gr.ChatInterface(fn=chat, examples=[\"침 흘림, 식사 거부, 입 냄새\", \"잦은 배변, 물 같은 변, 탈수\", \"구토, 설사, 체중 감소.\"], title=\"고양이 질병 AI 챗봇\", description=\"고양이의 질병과 증상에 대해 질문하면, 질병 정보와 응급상황 여부를 AI가 알려줍니다.\")\n",
    "            chat_demo\n",
    "\n",
    "        with gr.TabItem(\" 고양이 질병 자유형 AI 챗봇 \"):\n",
    "            with gr.Column(elem_classes=[\"chat-interface-container\"]):\n",
    "                # Div 추가하여 스타일 적용\n",
    "                gr.HTML(\"\"\"\n",
    "                    <div class=\"chat-title\">고양이 질병 자가진단 챗봇</div>\n",
    "                    <div class=\"description\">고양이 질병에 대해 자유롭게 질문하고 답변을 받아보세요.</div>\n",
    "                \"\"\")\n",
    "                chatbot = gr.ChatInterface(\n",
    "                    fn=conversational_chat,\n",
    "                    examples=[\n",
    "                        \"고양이가 식사 거부하고 침을 많이 흘려요.\",\n",
    "                        \"고양이가 복부에 이상이 있는 것 같아요.\",\n",
    "                        \"고양이의 증상에 대해 설명해주세요.\",\n",
    "                        \"고양이 범백혈구 감소증의 원인은 무엇인가요?\",\n",
    "                        \"고양이에게 흔한 질병은 무엇인가요?\"\n",
    "                    ]\n",
    "                ) # components 인자 제거\n",
    "\n",
    "demo.launch(server_port=7861, server_name=\"0.0.0.0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tap탭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\HJY310\\.venv\\lib\\site-packages\\gradio\\components\\chatbot.py:279: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from fuzzywuzzy import process\n",
    "import re\n",
    "\n",
    "# CSV 파일 로드 (경로를 실제 파일 경로로 변경해주세요)\n",
    "df = pd.read_csv(\"./data/cat_diseases.csv\", encoding='CP949')\n",
    "\n",
    "# Symptoms와 Description을 합쳐서 inputs 컬럼 생성\n",
    "df['inputs'] = df['Symptoms'].fillna('') + \" \" + df['Description'].fillna('')\n",
    "\n",
    "# 텍스트 분할\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "texts = text_splitter.split_text(\"\\n\".join(df['inputs']))\n",
    "\n",
    "# 임베딩 모델 초기화\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# 벡터 데이터베이스 생성\n",
    "vectorstore = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "# ChatOllama 모델 초기화 (temperature 값 조정)\n",
    "try:\n",
    "    llm = ChatOllama(model=\"gemma2\", temperature=0.0)\n",
    "except Exception as e:\n",
    "    print(f\"LLM 초기화 오류: {e}\")\n",
    "    llm = None\n",
    "\n",
    "# Question Generation Prompt\n",
    "question_generator_template = \"\"\"\n",
    "이전 대화 내역과 새로운 사용자 질문이 주어졌을 때, 검색을 위한 독립적인 질문으로 바꿔서 생성해주세요.\n",
    "\n",
    "이전 대화 내역:\n",
    "{chat_history}\n",
    "\n",
    "새로운 사용자 질문:\n",
    "{question}\n",
    "\n",
    "독립적인 질문:\n",
    "\"\"\"\n",
    "QUESTION_GENERATOR_PROMPT = PromptTemplate(input_variables=[\"chat_history\", \"question\"], template=question_generator_template)\n",
    "\n",
    "# Combine Documents Prompt (한국어 지시 강화 및 형식 명확화)\n",
    "combine_documents_template = \"\"\"\n",
    "당신은 경험 많은 고양이 수의사입니다. **모든 답변은 한국어만 사용하여, 어색함이 없도록 매우 자연스럽게 작성해야 합니다. 존댓말을 사용하여 정중하게 답변해야 합니다.** 외국어나 어색한 한국어 표현을 절대 사용하지 않도록 주의하십시오.\n",
    "\n",
    "사용자의 질문에 대해 다음과 같은 방식으로 답변해야 합니다.\n",
    "\n",
    "1.  질문에 대한 직접적인 답변을 **한국어로** 제공합니다.\n",
    "2.  필요한 경우, 추가적인 질문을 통해 상황을 명확히 파악하려고 노력해야 합니다. 예를 들어, 증상의 기간, 심각성, 다른 동반 증상 등을 **한국어로, 부드럽게** 물어볼 수 있습니다. (예: \"혹시 언제부터 그러셨나요?\", \"다른 불편한 점은 없으신가요?\")\n",
    "3.  가능한 원인 질병을 언급하고, 각 질병에 대한 간략한 설명을 **한국어로, 이해하기 쉽게** 제공합니다.\n",
    "4.  집에서 할 수 있는 조치와 동물병원 방문이 필요한 경우를 명확하게 구분하여 **한국어로, 친절하게** 안내합니다.\n",
    "5.  절대 진단이나 처방을 내리지 않고, 반드시 동물병원에 방문하여 정확한 진료를 받을 것을 **한국어로, 정중하게** 권장해야 합니다.\n",
    "6.  사용자가 걱정하거나 불안한 감정을 느낄 수 있기 때문에, **위로**와 **안심**을 주는 말을 포함하여 사용자가 더 편안하게 느끼도록 합니다.\n",
    "\n",
    "검색된 문서:\n",
    "{context}\n",
    "\n",
    "사용자 질문:\n",
    "{question}\n",
    "\n",
    "답변:\n",
    "\"\"\"\n",
    "COMBINE_DOCUMENTS_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"], template=combine_documents_template)\n",
    "\n",
    "# Chain 생성\n",
    "question_generator = LLMChain(llm=llm, prompt=QUESTION_GENERATOR_PROMPT)\n",
    "doc_chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=COMBINE_DOCUMENTS_PROMPT)\n",
    "\n",
    "qa = ConversationalRetrievalChain(\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 1}),\n",
    "    combine_docs_chain=doc_chain,\n",
    "    question_generator=question_generator,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "# 입력한 채팅 공백이나 특수문자 예외처리\n",
    "def clean_text(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.replace(\" \", \"\")\n",
    "    return text.lower()\n",
    "\n",
    "# 질병 정보 검색 함수\n",
    "def search_disease_info(message):\n",
    "    best_match = process.extractOne(message, df['inputs'])\n",
    "    if best_match and best_match[1] > 80:\n",
    "        disease_info = df.loc[df['inputs'] == best_match[0]]\n",
    "        disease_name = disease_info['Disease'].values[0]\n",
    "        symptoms = disease_info['Symptoms'].values[0]\n",
    "        description = disease_info['Description'].values[0]\n",
    "        emergency = disease_info['Emergency'].values[0]\n",
    "        return f\"질병: {disease_name}\\n증상: {symptoms}\\n설명: {description}\\n응급상황 여부: {emergency}\"\n",
    "    return \"해당 질문에 대한 답변을 찾을 수 없습니다.\"\n",
    "\n",
    "# 고양이 질병에 대한 정보 제공하는 채팅 함수\n",
    "def chat(message, history):\n",
    "    cleaned_message = clean_text(message)\n",
    "    disease_info = search_disease_info(message)\n",
    "    return disease_info\n",
    "\n",
    "# Conversational Chat 함수 구현 (chat_history 관리)\n",
    "def conversational_chat(message, history=[]):\n",
    "#def conversational_chat(message, history):\n",
    "    result = qa({\"question\": message, \"chat_history\": history})\n",
    "    history.append((message, result[\"answer\"]))\n",
    "    return result[\"answer\"]\n",
    "\n",
    "#def conversational_chat(message, history):\n",
    "    # 새로운 질문이 추가되기 전에 기존 history에서 동일한 질문이 있는지 체크\n",
    " #   if message not in [m for m, _ in history]:\n",
    " #       history.append((message, \"\"))\n",
    "    \n",
    "    # QA 수행\n",
    "  #  result = qa({\"question\": message, \"chat_history\": history})\n",
    "    \n",
    "    # 새로운 응답을 history에 추가\n",
    "  #  history[-1] = (message, result['answer'])\n",
    "    \n",
    "  #  return result['answer']\n",
    "\n",
    "# 세 번째 탭용 함수\n",
    "custom_prompt = \"\"\"\n",
    "당신은 고양이 질병에 대해 전문적인 수의사 역할을 합니다.\n",
    "아래 증상에 기반하여 가능한 질병과 관련 정보를 작성하세요:\n",
    "\n",
    "증상: {symptom}\n",
    "\n",
    "답변은 반드시 한국어로 작성하세요.\n",
    "\"\"\"\n",
    "PROMPT_TEMPLATE = PromptTemplate(input_variables=[\"symptom\"], template=custom_prompt)\n",
    "chain = LLMChain(llm=llm, prompt=PROMPT_TEMPLATE)\n",
    "\n",
    "def predict_from_form(symptom, age, duration):\n",
    "    prompt = f\"\"\"\n",
    "    고양이 나이: {age}\n",
    "    증상 발생 기간: {duration}일\n",
    "    증상: {symptom}\n",
    "    \n",
    "    위 정보를 기반으로 가능한 질병과 대처 방법을 작성하세요.\n",
    "    \"\"\"\n",
    "    response = chain.run(symptom=prompt)\n",
    "    return response\n",
    "\n",
    "# 드롭다운 기반 예측 함수\n",
    "def predict_disease_from_card(symptom):\n",
    "    best_match = process.extractOne(symptom, df['Symptoms'].dropna())\n",
    "    if best_match and best_match[1] > 80:\n",
    "        disease_info = df.loc[df['Symptoms'] == best_match[0]]\n",
    "        disease_name = disease_info['Disease'].values[0]\n",
    "        symptoms = disease_info['Symptoms'].values[0]\n",
    "        description = disease_info['Description'].values[0]\n",
    "        return f\"질병: {disease_name}\\n증상: {symptoms}\\n설명: {description}\"\n",
    "    return \"해당 증상에 대한 질병 정보를 찾을 수 없습니다.\"\n",
    "\n",
    "# Gradio 인터페이스 설정\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\" 고양이 질병 AI 챗봇 \"):\n",
    "            chat_demo = gr.ChatInterface(\n",
    "                fn=chat, \n",
    "                examples=[\n",
    "                    \"침 흘림, 식사 거부, 입 냄새\", \n",
    "                    \"잦은 배변, 물 같은 변, 탈수\", \n",
    "                    \"구토, 설사, 체중 감소.\"\n",
    "                ],\n",
    "                title=\"고양이 질병 AI 챗봇\",\n",
    "                description=\"고양이의 질병과 증상에 대해 질문하면, 질병 정보와 응급상황 여부를 AI가 알려줍니다.\"\n",
    "            )\n",
    "            chat_demo\n",
    "\n",
    "        with gr.TabItem(\" 고양이 질병 자유형 AI 챗봇 \"):\n",
    "            with gr.Column():\n",
    "                gr.HTML(\"\"\"\n",
    "                    <div style=\"text-align: center; font-size: 24px; color: #7193BD; font-weight: bold; margin-bottom: 15px;\">고양이 질병 자가진단 챗봇</div>\n",
    "                \"\"\")\n",
    "                chatbot = gr.ChatInterface(\n",
    "                    fn=conversational_chat,\n",
    "                    examples=[\n",
    "                        \"고양이가 식사 거부하고 침을 많이 흘려요.\",\n",
    "                        \"고양이가 복부에 이상이 있는 것 같아요.\",\n",
    "                        \"고양이의 증상에 대해 설명해주세요.\",\n",
    "                        \"고양이 범백혈구 감소증의 원인은 무엇인가요?\",\n",
    "                        \"고양이에게 흔한 질병은 무엇인가요?\"\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        with gr.TabItem(\" 고양이 질병 예측 - 양식 기반 \"):\n",
    "            gr.Markdown(\"## 🐾 고양이 질병 예측 서비스 - 양식 기반\")\n",
    "            gr.Markdown(\"### 고양이의 상태를 자세히 입력하세요.\")\n",
    "            symptom_input = gr.Textbox(label=\"증상 입력\", placeholder=\"예: 고양이가 밥을 안 먹고 구토를 해요.\")\n",
    "            age_input = gr.Number(label=\"고양이 나이 (년)\", value=3)\n",
    "            duration_input = gr.Number(label=\"증상 지속 기간 (일)\", value=1)\n",
    "\n",
    "            output_box = gr.Textbox(label=\"질병 진단 결과\", lines=10, interactive=False)\n",
    "            submit_button = gr.Button(\"진단 요청\")\n",
    "            submit_button.click(fn=predict_from_form, inputs=[symptom_input, age_input, duration_input], outputs=output_box)\n",
    "\n",
    "        with gr.TabItem(\" 고양이 질병 예측 - 드롭다운 기반 \"):\n",
    "            gr.Markdown(\"## 🐾 고양이 질병 예측 서비스 - 드롭다운 기반\")\n",
    "            gr.Markdown(\"### 고양이의 증상 중 하나를 드롭다운에서 선택하세요.\")\n",
    "            \n",
    "            # 증상 목록을 드롭다운에 추가\n",
    "            symptoms = df['Symptoms'].dropna().unique().tolist()\n",
    "            \n",
    "            symptom_dropdown = gr.Dropdown(choices=symptoms, label=\"증상 선택\", interactive=True)\n",
    "            output_box = gr.Textbox(label=\"질병 진단 결과\", lines=10, interactive=False)\n",
    "\n",
    "            submit_button = gr.Button(\"진단 요청\")\n",
    "            submit_button.click(fn=predict_disease_from_card, inputs=symptom_dropdown, outputs=output_box)\n",
    "\n",
    "demo.launch(server_port=7861, server_name=\"0.0.0.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\human-28\\AppData\\Local\\Temp\\ipykernel_12896\\1010872933.py:55: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = chain.run(input=user_input)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# CSV 파일 로드 (경로를 실제 파일 경로로 변경)\n",
    "df = pd.read_csv(\"./data/cat_diseases.csv\", encoding='CP949')\n",
    "\n",
    "# Symptoms와 Description 합치기\n",
    "df['inputs'] = df['Symptoms'].fillna('') + \" \" + df['Description'].fillna('')\n",
    "\n",
    "# 텍스트 분할\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "texts = text_splitter.split_text(\"\\n\".join(df['inputs']))\n",
    "\n",
    "# 임베딩 및 벡터 데이터베이스 초기화\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "# ChatOllama 모델 초기화\n",
    "try:\n",
    "    llm = ChatOllama(model=\"gemma2\", temperature=0.0)\n",
    "except Exception as e:\n",
    "    print(f\"LLM 초기화 오류: {e}\")\n",
    "    llm = None\n",
    "\n",
    "# 사용자 질문과 질병 정보를 바탕으로 답변 생성\n",
    "custom_prompt = \"\"\"\n",
    "당신은 고양이 질병에 대해 전문적인 수의사 역할을 합니다. \n",
    "사용자가 제공한 증상을 바탕으로 다음 정보를 작성하세요:\n",
    "\n",
    "1. 해당 증상에 대해 가능한 질병 목록을 생성하세요.\n",
    "2. 각 질병의 증상과 간략한 설명을 추가하세요.\n",
    "3. 응급상황인지 여부를 사용자에게 설명하고 필요한 조치를 안내하세요.\n",
    "4. 반드시 한국어로 작성하세요.\n",
    "\n",
    "사용자 입력: {input}\n",
    "\"\"\"\n",
    "PROMPT_TEMPLATE = PromptTemplate(\n",
    "    input_variables=[\"input\"], \n",
    "    template=custom_prompt\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=PROMPT_TEMPLATE)\n",
    "\n",
    "# Gradio 인터페이스 함수\n",
    "def predict_disease_info(user_input):\n",
    "    \"\"\"\n",
    "    사용자가 입력한 고양이 증상에 대해 LLM을 이용해 답변 생성.\n",
    "    \"\"\"\n",
    "    # LLM을 사용해 답변 생성\n",
    "    response = chain.run(input=user_input)\n",
    "    return response\n",
    "\n",
    "# Gradio 인터페이스 설정\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"## 🐾 고양이 질병 진단 서비스\")\n",
    "    gr.Markdown(\"### 고양이의 증상에 대해 입력하면, 가능한 질병 정보와 조언을 제공합니다.\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            user_input = gr.Textbox(label=\"고양이 증상 입력\", placeholder=\"예: 고양이가 밥을 안 먹고 구토를 해요.\")\n",
    "        with gr.Column():\n",
    "            output_text = gr.Textbox(label=\"진단 결과\", interactive=False)\n",
    "    \n",
    "    # 버튼 생성\n",
    "    submit_button = gr.Button(\"질병 예측하기\")\n",
    "    submit_button.click(fn=predict_disease_info, inputs=user_input, outputs=output_text)\n",
    "\n",
    "# 앱 실행\n",
    "demo.launch(server_port=7861, server_name=\"0.0.0.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv(\"./data/cat_diseases.csv\", encoding='CP949')\n",
    "\n",
    "# ChatOllama 초기화\n",
    "try:\n",
    "    llm = ChatOllama(model=\"gemma2\", temperature=0.0)\n",
    "except Exception as e:\n",
    "    print(f\"LLM 초기화 오류: {e}\")\n",
    "    llm = None\n",
    "\n",
    "# Prompt 설정\n",
    "custom_prompt = \"\"\"\n",
    "당신은 고양이 질병에 대해 전문적인 수의사 역할을 합니다.\n",
    "아래 증상에 기반하여 가능한 질병과 관련 정보를 작성하세요:\n",
    "\n",
    "증상: {symptom}\n",
    "\n",
    "답변은 반드시 한국어로 작성하세요.\n",
    "\"\"\"\n",
    "PROMPT_TEMPLATE = PromptTemplate(input_variables=[\"symptom\"], template=custom_prompt)\n",
    "chain = LLMChain(llm=llm, prompt=PROMPT_TEMPLATE)\n",
    "\n",
    "# Gradio 함수\n",
    "def predict_disease_from_card(selected_symptom):\n",
    "    response = chain.run(symptom=selected_symptom)\n",
    "    return response\n",
    "\n",
    "# Gradio UI 구성\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"## 🐾 고양이 질병 예측 서비스 - 카드 기반\")\n",
    "    gr.Markdown(\"### 고양이의 증상 중 하나를 선택하세요.\")\n",
    "    \n",
    "    # 증상 선택 카드\n",
    "    symptoms = df['Symptoms'].dropna().unique().tolist()\n",
    "    symptom_cards = gr.Radio(symptoms, label=\"증상 선택\", interactive=True)\n",
    "\n",
    "    # 출력\n",
    "    output_box = gr.Textbox(label=\"질병 진단 결과\", lines=10, interactive=False)\n",
    "    submit_button = gr.Button(\"진단 요청\")\n",
    "\n",
    "    submit_button.click(fn=predict_disease_from_card, inputs=symptom_cards, outputs=output_box)\n",
    "\n",
    "demo.launch(server_port=7861, server_name=\"0.0.0.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv(\"./data/cat_diseases.csv\", encoding='CP949')\n",
    "\n",
    "# ChatOllama 초기화\n",
    "try:\n",
    "    llm = ChatOllama(model=\"gemma2\", temperature=0.0)\n",
    "except Exception as e:\n",
    "    print(f\"LLM 초기화 오류: {e}\")\n",
    "    llm = None\n",
    "\n",
    "# Prompt 설정\n",
    "custom_prompt = \"\"\"\n",
    "당신은 고양이 질병에 대해 전문적인 수의사 역할을 합니다.\n",
    "아래 증상에 기반하여 가능한 질병과 관련 정보를 작성하세요:\n",
    "\n",
    "증상: {symptom}\n",
    "\n",
    "답변은 반드시 한국어로 작성하세요.\n",
    "\"\"\"\n",
    "PROMPT_TEMPLATE = PromptTemplate(input_variables=[\"symptom\"], template=custom_prompt)\n",
    "chain = LLMChain(llm=llm, prompt=PROMPT_TEMPLATE)\n",
    "\n",
    "def predict_from_form(symptom, age, duration):\n",
    "    prompt = f\"\"\"\n",
    "    고양이 나이: {age}\n",
    "    증상 발생 기간: {duration}일\n",
    "    증상: {symptom}\n",
    "    \n",
    "    위 정보를 기반으로 가능한 질병과 대처 방법을 작성하세요.\n",
    "    \"\"\"\n",
    "    response = chain.run(symptom=prompt)\n",
    "    return response\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"## 🐾 고양이 질병 예측 서비스 - 양식 기반\")\n",
    "    gr.Markdown(\"### 고양이의 상태를 자세히 입력하세요.\")\n",
    "    \n",
    "    # 양식 입력\n",
    "    symptom_input = gr.Textbox(label=\"증상 입력\", placeholder=\"예: 고양이가 밥을 안 먹고 구토를 해요.\")\n",
    "    age_input = gr.Number(label=\"고양이 나이 (년)\", value=3)\n",
    "    duration_input = gr.Number(label=\"증상 지속 기간 (일)\", value=1)\n",
    "\n",
    "    output_box = gr.Textbox(label=\"질병 진단 결과\", lines=10, interactive=False)\n",
    "    submit_button = gr.Button(\"진단 요청\")\n",
    "\n",
    "    submit_button.click(fn=predict_from_form, inputs=[symptom_input, age_input, duration_input], outputs=output_box)\n",
    "\n",
    "\n",
    "demo.launch(server_port=7861, server_name=\"0.0.0.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\HJY310\\.venv\\lib\\site-packages\\gradio\\components\\chatbot.py:279: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7861\n",
      "* Running on public URL: https://7e63215a51307fd172.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://7e63215a51307fd172.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from fuzzywuzzy import process\n",
    "import re\n",
    "\n",
    "# CSV 파일 로드 (경로를 실제 파일 경로로 변경해주세요)\n",
    "df = pd.read_csv(\"./data/cat_diseases.csv\", encoding='CP949')\n",
    "\n",
    "# Symptoms와 Description을 합쳐서 inputs 컬럼 생성\n",
    "df['inputs'] = df['Symptoms'].fillna('') + \" \" + df['Description'].fillna('')\n",
    "\n",
    "# 텍스트 분할\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "texts = text_splitter.split_text(\"\\n\".join(df['inputs']))\n",
    "\n",
    "# 임베딩 모델 초기화\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# 벡터 데이터베이스 생성\n",
    "vectorstore = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "# ChatOllama 모델 초기화 (temperature 값 조정)\n",
    "try:\n",
    "    llm = ChatOllama(model=\"gemma2\", temperature=0.0)\n",
    "except Exception as e:\n",
    "    print(f\"LLM 초기화 오류: {e}\")\n",
    "    llm = None\n",
    "\n",
    "# Question Generation Prompt\n",
    "question_generator_template = \"\"\"\n",
    "이전 대화 내역과 새로운 사용자 질문이 주어졌을 때, 검색을 위한 독립적인 질문으로 바꿔서 생성해주세요.\n",
    "\n",
    "이전 대화 내역:\n",
    "{chat_history}\n",
    "\n",
    "새로운 사용자 질문:\n",
    "{question}\n",
    "\n",
    "독립적인 질문:\n",
    "\"\"\"\n",
    "QUESTION_GENERATOR_PROMPT = PromptTemplate(input_variables=[\"chat_history\", \"question\"], template=question_generator_template)\n",
    "\n",
    "# Combine Documents Prompt (한국어 지시 강화 및 형식 명확화)\n",
    "combine_documents_template = \"\"\"\n",
    "당신은 경험 많은 고양이 수의사입니다. **모든 답변은 한국어만 사용하여, 어색함이 없도록 매우 자연스럽게 작성해야 합니다. 존댓말을 사용하여 정중하게 답변해야 합니다.** 외국어나 어색한 한국어 표현을 절대 사용하지 않도록 주의하십시오.\n",
    "\n",
    "사용자의 질문에 대해 다음과 같은 방식으로 답변해야 합니다.\n",
    "\n",
    "1.  질문에 대한 직접적인 답변을 **한국어로** 제공합니다.\n",
    "2.  필요한 경우, 추가적인 질문을 통해 상황을 명확히 파악하려고 노력해야 합니다. 예를 들어, 증상의 기간, 심각성, 다른 동반 증상 등을 **한국어로, 부드럽게** 물어볼 수 있습니다. (예: \"혹시 언제부터 그러셨나요?\", \"다른 불편한 점은 없으신가요?\")\n",
    "3.  가능한 원인 질병을 언급하고, 각 질병에 대한 간략한 설명을 **한국어로, 이해하기 쉽게** 제공합니다.\n",
    "4.  집에서 할 수 있는 조치와 동물병원 방문이 필요한 경우를 명확하게 구분하여 **한국어로, 친절하게** 안내합니다.\n",
    "5.  절대 진단이나 처방을 내리지 않고, 반드시 동물병원에 방문하여 정확한 진료를 받을 것을 **한국어로, 정중하게** 권장해야 합니다.\n",
    "6.  사용자가 걱정하거나 불안한 감정을 느낄 수 있기 때문에, **위로**와 **안심**을 주는 말을 포함하여 사용자가 더 편안하게 느끼도록 합니다.\n",
    "\n",
    "검색된 문서:\n",
    "{context}\n",
    "\n",
    "사용자 질문:\n",
    "{question}\n",
    "\n",
    "답변:\n",
    "\"\"\"\n",
    "COMBINE_DOCUMENTS_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"], template=combine_documents_template)\n",
    "\n",
    "# Chain 생성\n",
    "question_generator = LLMChain(llm=llm, prompt=QUESTION_GENERATOR_PROMPT)\n",
    "doc_chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=COMBINE_DOCUMENTS_PROMPT)\n",
    "\n",
    "qa = ConversationalRetrievalChain(\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 1}),\n",
    "    combine_docs_chain=doc_chain,\n",
    "    question_generator=question_generator,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "# 입력한 채팅 공백이나 특수문자 예외처리\n",
    "def clean_text(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.replace(\" \", \"\")\n",
    "    return text.lower()\n",
    "\n",
    "# 고양이 질병에 대한 정보 제공하는 채팅 함수\n",
    "def chat(message, history):\n",
    "    cleaned_message = clean_text(message)\n",
    "    disease_info = search_disease_info(message)\n",
    "    return disease_info\n",
    "\n",
    "# Conversational Chat 함수 구현 (chat_history 관리)\n",
    "def conversational_chat(message, history):\n",
    "    # QA 수행\n",
    "    result = qa({\"question\": message, \"chat_history\": history})\n",
    "    \n",
    "    # Gradio가 history를 관리하므로 history를 직접 업데이트하지 않음\n",
    "    response = result[\"answer\"]\n",
    "    return response  # 응답만 반환\n",
    "\n",
    "# 세 번째 탭용 함수\n",
    "custom_prompt = \"\"\"\n",
    "당신은 고양이 질병에 대해 전문적인 수의사 역할을 합니다.\n",
    "아래 증상에 기반하여 가능한 질병과 관련 정보를 작성하세요:\n",
    "\n",
    "증상: {symptom}\n",
    "\n",
    "답변은 반드시 한국어로 작성하세요.\n",
    "\"\"\"\n",
    "PROMPT_TEMPLATE = PromptTemplate(input_variables=[\"symptom\"], template=custom_prompt)\n",
    "chain = LLMChain(llm=llm, prompt=PROMPT_TEMPLATE)\n",
    "\n",
    "def predict_from_form(symptom, age, duration):\n",
    "    prompt = f\"\"\"\n",
    "    고양이 나이: {age}\n",
    "    증상 발생 기간: {duration}일\n",
    "    증상: {symptom}\n",
    "    \n",
    "    위 정보를 기반으로 가능한 질병과 대처 방법을 작성하세요.\n",
    "    \"\"\"\n",
    "    response = chain.run(symptom=prompt)\n",
    "    return response\n",
    "\n",
    "# 드롭다운 기반 예측 함수\n",
    "def predict_disease_from_card(symptom):\n",
    "    best_match = process.extractOne(symptom, df['Symptoms'].dropna())\n",
    "    if best_match and best_match[1] > 80:\n",
    "        disease_info = df.loc[df['Symptoms'] == best_match[0]]\n",
    "        disease_name = disease_info['Disease'].values[0]\n",
    "        symptoms = disease_info['Symptoms'].values[0]\n",
    "        description = disease_info['Description'].values[0]\n",
    "        return f\"질병: {disease_name}\\n증상: {symptoms}\\n설명: {description}\"\n",
    "    return \"해당 증상에 대한 질병 정보를 찾을 수 없습니다.\"\n",
    "\n",
    "# Gradio 인터페이스 설정\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\" 고양이 질병 자유형 AI 챗봇 \"):\n",
    "            with gr.Column():\n",
    "                gr.HTML(\"\"\"\n",
    "                    <div style=\"text-align: center; font-size: 24px; color: #7193BD; font-weight: bold; margin-bottom: 15px;\">고양이 질병 자가진단 챗봇</div>\n",
    "                \"\"\")\n",
    "                chatbot = gr.ChatInterface(\n",
    "                    fn=conversational_chat,\n",
    "                    examples=[\n",
    "                        \"고양이가 식사 거부하고 침을 많이 흘려요.\",\n",
    "                        \"고양이가 복부에 이상이 있는 것 같아요.\",\n",
    "                        \"고양이의 증상에 대해 설명해주세요.\",\n",
    "                        \"고양이 범백혈구 감소증의 원인은 무엇인가요?\",\n",
    "                        \"고양이에게 흔한 질병은 무엇인가요?\"\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        with gr.TabItem(\" 고양이 질병 예측 - 양식 기반 \"):\n",
    "            gr.Markdown(\"## 🐾 고양이 질병 예측 서비스 - 양식 기반\")\n",
    "            gr.Markdown(\"### 고양이의 상태를 자세히 입력하세요.\")\n",
    "            symptom_input = gr.Textbox(label=\"증상 입력\", placeholder=\"예: 고양이가 밥을 안 먹고 구토를 해요.\")\n",
    "            age_input = gr.Number(label=\"고양이 나이 (년)\", value=3)\n",
    "            duration_input = gr.Number(label=\"증상 지속 기간 (일)\", value=1)\n",
    "\n",
    "            output_box = gr.Textbox(label=\"질병 진단 결과\", lines=10, interactive=False)\n",
    "            submit_button = gr.Button(\"진단 요청\")\n",
    "            submit_button.click(fn=predict_from_form, inputs=[symptom_input, age_input, duration_input], outputs=output_box)\n",
    "\n",
    "        with gr.TabItem(\" 고양이 질병 예측 - 드롭다운 기반 \"):\n",
    "            gr.Markdown(\"## 🐾 고양이 질병 예측 서비스 - 드롭다운 기반\")\n",
    "            gr.Markdown(\"### 고양이의 증상 중 하나를 드롭다운에서 선택하세요.\")\n",
    "            \n",
    "            # 증상 목록을 드롭다운에 추가\n",
    "            symptoms = df['Symptoms'].dropna().unique().tolist()\n",
    "            \n",
    "            symptom_dropdown = gr.Dropdown(choices=symptoms, label=\"증상 선택\", interactive=True)\n",
    "            output_box = gr.Textbox(label=\"질병 진단 결과\", lines=10, interactive=False)\n",
    "\n",
    "            submit_button = gr.Button(\"진단 요청\")\n",
    "            submit_button.click(fn=predict_disease_from_card, inputs=symptom_dropdown, outputs=output_box)\n",
    "\n",
    "demo.launch(server_port=7861, server_name=\"0.0.0.0\", share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
